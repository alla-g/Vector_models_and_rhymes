{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import nltk.data\n",
    "import logging\n",
    "from os.path import join\n",
    "from gensim.models import word2vec\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors collected: 228635\n"
     ]
    }
   ],
   "source": [
    "# find all files\n",
    "# path = your path\n",
    "paths = []\n",
    "for i in os.walk(path):\n",
    "    paths.append(i)\n",
    "authors = paths[0][2]\n",
    "print('Authors collected:', len(authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Base' corpus with no added tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nur = re.compile('нур ?')\n",
    "with open('stihi.ru_corpus.txt', 'w', encoding='UTF-8') as F:\n",
    "    for a in authors:\n",
    "        title = r'C:\\Users\\User\\Desktop\\универ\\курсовая\\stihi_ru_makup_lemmed\\stihi_ru_makup_lemmed\\\\' + a\n",
    "        with open(title, encoding='UTF-8') as f:\n",
    "            t = f.read()\n",
    "        poem = re.sub('(<.*>|\\n|\\?)', '', t)\n",
    "        sent = sent_tokenize(poem)\n",
    "        lem_sent = []        \n",
    "        for s in sent:\n",
    "            lemmas = re.findall(r'{(.*?)}', s)\n",
    "            lem_sent.append(' '.join(lemmas))\n",
    "        corp = '\\n'.join(lem_sent)\n",
    "        corpus = re.sub(nur, ' ', corp)\n",
    "        c = F.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus with /RHYME tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 36min 17s\n"
     ]
    }
   ],
   "source": [
    "re_meta = re.compile('(<.*>|\\?|\\t(.*))')\n",
    "re_zone = re.compile('{(\\w*)}(\\W*)$', re.MULTILINE)\n",
    "rhyme = r'{\\1/RHYME}\\2'\n",
    "re_lemmas = re.compile('{(.*?)}')\n",
    "with open('stihi.ru_corpusRHYMED.txt', 'w', encoding='UTF-8') as F:\n",
    "    for a in authors:\n",
    "        title = r'C:\\Users\\User\\Desktop\\универ\\курсовая\\stihi_ru_makup_lemmed\\stihi_ru_makup_lemmed\\\\' + a\n",
    "        with open(title, encoding='UTF-8') as f:\n",
    "            t = f.read()\n",
    "        poem = re.sub(re_meta, '', t)\n",
    "        poem = re.sub(re_zone, rhyme, poem)\n",
    "        sent = sent_tokenize(poem)\n",
    "        lem_sent = []\n",
    "        for s in sent:\n",
    "            lemmas = re.findall(re_lemmas, s)\n",
    "            lem_sent.append(' '.join(lemmas))\n",
    "        corpus = '\\n'.join(lem_sent)\n",
    "        c = F.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only-rhyme corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "re_meta = re.compile('(<.*>|\\?|\\t(.*))')\n",
    "re_rhyme = re.compile(r'{(\\w*)}\\W*$', re.MULTILINE)\n",
    "with open('stihi.ru_rhyme_corpus.txt', 'w', encoding='UTF-8') as F:\n",
    "    for a in authors:\n",
    "        title = r'C:\\Users\\User\\Desktop\\универ\\курсовая\\stihi_ru_makup_lemmed\\stihi_ru_makup_lemmed\\\\' + a\n",
    "        with open(title, encoding='UTF-8') as f:\n",
    "            t = f.read()\n",
    "        poem = re.sub(re_meta, '', t)\n",
    "        stanza = poem.split('\\n\\n')\n",
    "        poem_rhymes = []\n",
    "        for s in stanza:\n",
    "            st_rhymes = re.findall(re_rhyme, s)\n",
    "            poem_rhymes.append(' '.join(st_rhymes))\n",
    "        corpus = '\\n'.join(poem_rhymes)\n",
    "        c = F.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating vector models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Base' corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'stihi.ru_corpus.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# window = 2\n",
    "model = gensim.models.Word2Vec(data, size=300, window=2, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruWIN2.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 5\n",
    "model = gensim.models.Word2Vec(data, size=300, window=5, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruWIN5.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 8\n",
    "model = gensim.models.Word2Vec(data, size=300, window=8, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruWIN8.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 15\n",
    "model = gensim.models.Word2Vec(data, size=300, window=15, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruWIN15.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus with /RHYME tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'stihi.ru_corpusRHYMED.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 2\n",
    "model = gensim.models.Word2Vec(data, size=300, window=2, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruRHYMEDWIN2.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 5\n",
    "model = gensim.models.Word2Vec(data, size=300, window=5, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruRHYMEDWIN5.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 8\n",
    "model = gensim.models.Word2Vec(data, size=300, window=8, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruRHYMEDWIN8.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 15\n",
    "model = gensim.models.Word2Vec(data, size=300, window=15, min_count=1000, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.ruRHYMEDWIN15.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only-rhyme corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'stihi.ru_rhyme_corpus.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 2\n",
    "model = gensim.models.Word2Vec(data, size=300, window=2, min_count=1, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.rurhymesWIN2.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 5\n",
    "model = gensim.models.Word2Vec(data, size=300, window=5, min_count=1, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.rurhymesWIN5.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 7\n",
    "model = gensim.models.Word2Vec(data, size=300, window=7, min_count=1, workers=4, iter=5)\n",
    "model.init_sims(replace=True)\n",
    "model_path = \"model_stihi.rurhymesWIN7.bin\"\n",
    "model.wv.save_word2vec_format(model_path, binary=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
